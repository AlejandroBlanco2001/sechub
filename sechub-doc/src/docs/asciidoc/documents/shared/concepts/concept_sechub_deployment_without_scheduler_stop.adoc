// SPDX-License-Identifier: MIT
[[section-shared-concepts-sechub-deployment-without-scheduler-stop]]
*Why this concept is necessary*
 
Before this concept, for new deployments of {sechub} server instances, administrators had to
stop the scheduler and  wait for running jobs to finish. After no jobs were running any longer, 
the deployment was triggered and after this the scheduler was enabled again and job processing 
started again.

This works always, but has a catch: If there are many running jobs it can take a while until all
of those running jobs are done. And also in the mean time no new jobs are started. This means that 
when we have a great count of running jobs, the time gap between deployment and start of new
jobs increases. 

CI/CD builds or any other use of SecHub takes longer in the meantime, which can be unpleasant /
a bad user experience.

===== SIGTERM handling

plantuml::diagrams/diagram_sechub_sigterm_handling.puml[format=svg, title="SIGTERM handling"] 

K8s and other systems will send a `SIGTERM` signal to give application the possibility to shutdown
gracefully. 

On a `SIGTERM` signal {sechub} temporarily suspends a job, allowing its {pds} instances to continue 
processing it in the background. The next new SecHub server then reactivates the job and proceeds 
with the results from the {pds} instances (or wait for them if still not already available).

All running {sechub} jobs on terminating instance are marked with execution state `SUSPENDED` +
(similar to cancel) which will also update `ENDED` timestamp on job.

Other servers instances will restart `SUSPENDED` jobs by existing 
<<section-shared-concepts-sechub-job-restart-handling,restart mechanism>>  (but `SUSPENDED` will 
be handled before `READY_TO_START`).

To prevent too fast restarts, the `ENDED` timestamp of {sechub} job will be inspected on suspended jobs
and only fetched as next job when the time gap is greater than a defined (configurable) time period. 

